{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Paleofuturistic Python The Python development workflow your past self had always hoped for is finally here! This is a detached fork of Straight to the Money \ud83d\udcb0 . Check it out if this template is a bit too involved for you and you want to go with something more simple. Usage Prerequisite: uv (Installing uv should also provide you with uvx. Give their docs a look-over before continuing if you want to get a better understanding of what is going on under the hood in the steps below.) Setup Initialize with uvx cruft create --checkout latest https://github.com/schubergphilis/paleofuturistic_python and fill in your project details. Optional: validate the setup with uv run python -c \"import paleofuturistic_python; print(paleofuturistic_python.hello())\" (replace paleofuturistic_python with your project name/slug). Run uv sync --all-extras --dev to download the dependencies and generate a .lock file. Workflow Download dependencies (if you need any): uv add some_lib_you_need Develop (optional, tinker: uvx --with-editable . ptpython ) QA: Format: uv run ruff format Lint: uv run ruff check Type check: uv run mypy Test: uv run python -m unittest Build: uv build Document: uvx --with mkdocstrings[python] mkdocs build Publish: uv publish Can it really be that simple? Well, eventually yes, but you will need to set up some connections and credentials still, of course. For a slightly more elaborate walkthrough on that, see the docs . Still skeptical? See the about instead. Or, have a look at a kitchen sink project created with this template.","title":"Home"},{"location":"#paleofuturistic-python","text":"The Python development workflow your past self had always hoped for is finally here! This is a detached fork of Straight to the Money \ud83d\udcb0 . Check it out if this template is a bit too involved for you and you want to go with something more simple.","title":"Paleofuturistic Python"},{"location":"#usage","text":"Prerequisite: uv (Installing uv should also provide you with uvx. Give their docs a look-over before continuing if you want to get a better understanding of what is going on under the hood in the steps below.)","title":"Usage"},{"location":"#setup","text":"Initialize with uvx cruft create --checkout latest https://github.com/schubergphilis/paleofuturistic_python and fill in your project details. Optional: validate the setup with uv run python -c \"import paleofuturistic_python; print(paleofuturistic_python.hello())\" (replace paleofuturistic_python with your project name/slug). Run uv sync --all-extras --dev to download the dependencies and generate a .lock file.","title":"Setup"},{"location":"#workflow","text":"Download dependencies (if you need any): uv add some_lib_you_need Develop (optional, tinker: uvx --with-editable . ptpython ) QA: Format: uv run ruff format Lint: uv run ruff check Type check: uv run mypy Test: uv run python -m unittest Build: uv build Document: uvx --with mkdocstrings[python] mkdocs build Publish: uv publish Can it really be that simple? Well, eventually yes, but you will need to set up some connections and credentials still, of course. For a slightly more elaborate walkthrough on that, see the docs . Still skeptical? See the about instead. Or, have a look at a kitchen sink project created with this template.","title":"Workflow"},{"location":"about/","text":"About This is a detached fork of Straight to the Money \ud83d\udcb0 . Check it out if this template is a bit too involved for you and you want to go with something more simple.","title":"About"},{"location":"about/#about","text":"This is a detached fork of Straight to the Money \ud83d\udcb0 . Check it out if this template is a bit too involved for you and you want to go with something more simple.","title":"About"},{"location":"extra_guides/","text":"Extra guides Update your Paleofuturistic boilerplate If this template gets updated and you want to benefit from the new features, follow the steps below: Go to the command-line in your local clone of your project. Execute uvx cruft update . The steps after that should be self-explanatory, but there is always more information available dor those who want . GitHub security enhancements Note you have just bestowed great power upon GitHub. With great power comes... No wait we have something serious to say here! If you followed the guides linked above you will have already setup a separate GitHub env for publishing and made use of PyPI's trusted publishing. That's great, but it's advisable to put up an even higher fence against attacks. You can for example use the following settings to protect your repository from outsiders: Protect at least the main branch and v* tags with rulesets; configure them to enforce updates via peer-reviewed pull requests from forks. Enable \"Limit to users explicitly granted read or higher access\" under \"Code review limits\". Set \"Require approval for all external contributors\" under \"Actions permissions\" -> \"Approval for running fork pull request workflows from contributors\". Set \"Read repository contents and packages permissions\" (no default repo write) under \"Actions permissions\" -> \"Workflow permissions\". Uncheck \"Allow GitHub Actions to create and approve pull requests\" under \"Actions permissions\" -> \"Workflow permissions\". You could even go as far as setting \"Temporary interaction limits\" under \"Interaction limits\". Protecting your repository from insider threats is far harder, but this might help: Set some \"Required reviewers\" under \"Environments\" -> \"Deployment protection rules\". Cumbersome to implement, but effective: org/repo admin access only for non-personal accounts which require 4-eyes approval for assuming. Executable apps This workflow template was created for libraries, because those are usually the most involved to get going. Making the template able to produce Python apps is not much work luckily. (Making stand-alone apps is a whole other story though! In that case you may want to look at PyInstaller or Nuitka for example.) To make the package an executable module that supports something like python -m <YOUR_PROJECT_SLUG> (or uv run --isolated --no-project --with <YOUR_PROJECT_SLUG> python -m <YOUR_PROJECT_SLUG> ) create a __main__.py that looks something like: from <YOUR_PROJECT_SLUG> import hello def main() -> None: print(hello()) if __name__ == \"__main__\": main() Then to make tools like uvx and pipx be able to execute the module like so uvx --with <YOUR_PROJECT_SLUG> add the following to the pyproject.toml . [project.scripts] <YOUR_PROJECT_SLUG> = \"<YOUR_PROJECT_SLUG>.__main__:main\" If you are setting out to build an app, you can implement all the boilerplate yourself with os and argparse . You could also look into available frameworks, for example for CLIs: Typer .","title":"Extra guides"},{"location":"extra_guides/#extra-guides","text":"","title":"Extra guides"},{"location":"extra_guides/#update-your-paleofuturistic-boilerplate","text":"If this template gets updated and you want to benefit from the new features, follow the steps below: Go to the command-line in your local clone of your project. Execute uvx cruft update . The steps after that should be self-explanatory, but there is always more information available dor those who want .","title":"Update your Paleofuturistic boilerplate"},{"location":"extra_guides/#github-security-enhancements","text":"Note you have just bestowed great power upon GitHub. With great power comes... No wait we have something serious to say here! If you followed the guides linked above you will have already setup a separate GitHub env for publishing and made use of PyPI's trusted publishing. That's great, but it's advisable to put up an even higher fence against attacks. You can for example use the following settings to protect your repository from outsiders: Protect at least the main branch and v* tags with rulesets; configure them to enforce updates via peer-reviewed pull requests from forks. Enable \"Limit to users explicitly granted read or higher access\" under \"Code review limits\". Set \"Require approval for all external contributors\" under \"Actions permissions\" -> \"Approval for running fork pull request workflows from contributors\". Set \"Read repository contents and packages permissions\" (no default repo write) under \"Actions permissions\" -> \"Workflow permissions\". Uncheck \"Allow GitHub Actions to create and approve pull requests\" under \"Actions permissions\" -> \"Workflow permissions\". You could even go as far as setting \"Temporary interaction limits\" under \"Interaction limits\". Protecting your repository from insider threats is far harder, but this might help: Set some \"Required reviewers\" under \"Environments\" -> \"Deployment protection rules\". Cumbersome to implement, but effective: org/repo admin access only for non-personal accounts which require 4-eyes approval for assuming.","title":"GitHub security enhancements"},{"location":"extra_guides/#executable-apps","text":"This workflow template was created for libraries, because those are usually the most involved to get going. Making the template able to produce Python apps is not much work luckily. (Making stand-alone apps is a whole other story though! In that case you may want to look at PyInstaller or Nuitka for example.) To make the package an executable module that supports something like python -m <YOUR_PROJECT_SLUG> (or uv run --isolated --no-project --with <YOUR_PROJECT_SLUG> python -m <YOUR_PROJECT_SLUG> ) create a __main__.py that looks something like: from <YOUR_PROJECT_SLUG> import hello def main() -> None: print(hello()) if __name__ == \"__main__\": main() Then to make tools like uvx and pipx be able to execute the module like so uvx --with <YOUR_PROJECT_SLUG> add the following to the pyproject.toml . [project.scripts] <YOUR_PROJECT_SLUG> = \"<YOUR_PROJECT_SLUG>.__main__:main\" If you are setting out to build an app, you can implement all the boilerplate yourself with os and argparse . You could also look into available frameworks, for example for CLIs: Typer .","title":"Executable apps"},{"location":"walkthrough/","text":"Walkthrough Some things in usage might require a little more effort on the first run. Let's go over the bootstrapping and the development cycle in full detail. In this walkthrough we are going to create a Python library and publish it to PyPI. While doing so we will do all the steps you would normally do during a feature development as well. Also, we will publish the project's documentation to GitHub Pages. You are encouraged to go through this walkthrough twice. Upon first run, only execute the instructions and ignore all the explanations underneath. Then reread this page in full to get a better grasp of what this template is setting you up for you. Initializing your project Instructions: Create a repository in GitHub; do not add any additional files upon creation, like .gitignore, LICENSE etc.; make sure you take a project name not already on PyPI, if you want to follow this walkthrough all the way to publishing there. Clone the repo to your development environment. Execute this command from the directory directly above: uvx cruft create -f --checkout latest https://github.com/schubergphilis/paleofuturistic_python . Answer the questions; project_slug should be the same as the GitHub repository name you chose. cd to your project directory; execute git add --all , git commit -m \"initial commit\" and git push . Navigate to https://github.com/<YOUR_GITHUB_HANDLE>/<YOUR_PROJECT_SLUG>/actions . See that the quality assurance CI fails; you will fix this in the next instructions. Managing boilerplate cruft ( cookiecutter under its hood) is a tool for managing boilerplate. Like you did, new projects can be instantiated from a template with it. An even more amazing function is that it can update a project's boilerplate when the template changes (also this Paleofuturistic one!). See the extra guides for more information on that. It might still be noteworthy to point out a few things in the command you used: uvx cruft create -f --checkout latest https://github.com/schubergphilis/paleofuturistic_python The --checkout latest in there should speak for itself. Now mind the -f . cruft does not allow editing an existing directory by default for safety. Because we just cloned an empty repository, we can assume to be safe though. Other options to get to the same state would be: create the project with directory from the template with cruft, cd to it; git init, add all, commit, set the remote and push. create the project with directory from the template with cruft, copy the contents to a cloned repository; git add all, commit and push. Reviewing .gitignore and LICENSE If you had wanted another license than Apache, you have probably already chosen one and can easily override the templated one (if you do, do it in the pyproject.toml as well). Maybe take a look at the .gitignore, maybe not; it's fine; I promise. Dependency management Instructions: Get back to the command-line in your local clone. Execute: uv sync --all-extras --dev . Execute: git add --all , git commit -m \"lock initial dependencies\" and git push . Navigate to https://github.com/<YOUR_GITHUB_HANDLE>/<YOUR_PROJECT_SLUG>/actions . See that the quality assurance CI now succeeds; what it's exactly doing, you will find out in the next instructions. Dependencies in environments Usually a lot or even more of the low-level functionality you need for what you want to develop is already available. Luckily, reeling that good stuff in is one of uv's strengths. The --all-extras --dev flags from the uv command above triggers downloading optional and development dependencies respectively. After that you can add dependencies like for example uv add requests or uv add --dev pytest for dev dependencies. These commands do everything you would hope they would do by default. Yes, that includes caching and project-based environment isolation. For starters just adding some dependencies from PyPI is probably all you want. All the other things you would want from (uv's) dependency management you can always look into later. By now you might have already guessed that uv acts on dependencies in your environment and uvx is meant for tools that live outside of it. A reminder: add the names of the public features you develop to the __all__ list in __init__.py . This way others (that includes your unittest runs) can conveniently access them upon importing your module. Quality assurance Instructions: Get back to the command-line in your local clone. Execute uv run ruff format --diff ; should output 4 files already formatted . Execute uv run ruff check ; should output All checks passed! . Execute uv run mypy ; should output Success: no issues found in 2 source files . Execute uv run python -m unittest ; gives multiline output, should end with OK . Execute git status ; gives multiline output, should end with nothing to commit, working tree clean . Formatting, linting, type checking and testing The steps above are the minimal steps to assure quality in any software project. When they output that everything is as expected, they should also leave the codebase unchanged. The dependencies for these steps are pinned in the pyproject.toml to make sure they run the same way locally as in the pipeline. The pipeline can run quite quick upon repetition, because caching is enabled, see .github/workflows/quality_assurance.yaml . Formatting ( uv run ruff format --diff ), type checking ( uv run mypy ) and testing ( uv run python -m unittest ) should speak for themselves. The ruff formatter, mypy and Python's build-in testing library are ubiquitous and easy to use. Only mypy has a minimal amount of config in the pyproject.toml that make it a bit more specific and tight. You can get into the weeds very fast with linting ( uv run ruff check ) though. If you go with the flow of this template it's probably going to work out fine for your first 1,000 commits or so. And by that time you can probably figure out how to stop a pesky linter from undoing your intricacies, so my advice would be to not give it too much thought. (If you feel like getting into the weeds early though, have at you .) Small thing worth mentioning is that the pyproject.toml is setup such that the ruff linter and formatter should not contradict each other. Also, the activated linting rules are a little more than the default, mainly because isort is really convenient. Building your package Instructions: Get back to the command-line in your local clone. Execute uv build ; gives multiline output, should end with Successfully built dist/<YOUR_PROJECT_SLUG>-0.1.0-py3-none-any.whl . Execute git status ; gives multiline output, should end with nothing to commit, working tree clean . The artifacts to distribute uv has its own build backend nowadays. It works only for pure Python projects at the moment, but that's probably good enough for most projects. If you have more special needs you probably already know what you want and can configure that under [build-system] in the pyproject.toml . Also, uv is not so sure the build backend won't significantly change in the future. For that reason there is an upper limit in the pyproject.toml on uv's minor version as per their best practices. (If you ever update uv beyond that version and this breaks your build step for that reason, check back on this template and update .) Other than that, this step should simply be a uv build command that just works. Locally you will probably only run this command to validate it works though. Eventually it's a pipeline that should build and publish. Previewing and publishing your documentation Instructions: Get back to the command-line in your local clone. Execute uvx --with mkdocstrings[python] mkdocs build ; gives multiline output, should end with INFO - Documentation built in <X> seconds . Execute uvx --with mkdocstrings[python] mkdocs serve ; gives multiline output, should end with INFO - <X> Serving on http://127.0.0.1:8000/ ; Navigate to http://127.0.0.1:8000/ ; some rudimentary documentation should be there. Get back to the command-line in your local clone; terminate the serving process. Execute uvx --with mkdocstrings[python] mkdocs gh-deploy ; gives multiline output, should end with INFO - Your documentation should shortly be available at: https://<YOUR_GITHUB_HANDLE>.github.io/<YOUR_PROJECT_SLUG>/ . Navigate to https://github.com/<YOUR_GITHUB_HANDLE>/<YOUR_PROJECT_SLUG>/actions ; a GitHub Action should be running to deploy you docs. Wait until the action finishes then navigate to https://<YOUR_GITHUB_HANDLE>.github.io/<YOUR_PROJECT_SLUG>/ ; it should display the same documentation you just served locally. Get back to the command-line in your local clone. Execute git status ; gives multiline output, should end with nothing to commit, working tree clean . A very feature-rich static website Let's first explain a bit about that magic --with in the commands above. It injects additional dependencies into the environment in this case mkdocstrings with its python add-on. Now, in your project directory go to docs/index.md and see how little was needed to produce such a fantastic skeleton for documentation. You do need to keep every docstring nice and tidy to make that work though. I found mkdocstrings works best with numpy style docs, so that's the template's default. You can change that and more in the mkdocs.yaml . Don't try to understand all of that at once... MkDocs offers far more than everything you accomplished above, especially combined with even more plugins. See for yourself. Personal favorite out of the box: watch files. Others might particularly like automated publishing to other documentation hosting parties than GitHub Pages. Publishing your Python package to PyPI Instructions: Navigate to https://github.com/<YOUR_GITHUB_HANDLE>/<YOUR_PROJECT_SLUG>/settings/environments . Create an environment named pypi . Go to PyPI and login; if you have no account there, create one first. Configure a trusted publisher . Go to https://github.com/<YOUR_GITHUB_HANDLE>/<YOUR_PROJECT_SLUG>/actions/workflows/release.yaml and run the workflow. Wait for the workflow to finish, then get back to the command-line. Execute uv run --isolated --no-project --with <YOUR_PROJECT_SLUG> python -c \"from <YOUR_PROJECT_SLUG> import hello; print(hello())\" ; should output Hello you from <YOUR_PROJECT_SLUG>! . Beyond v0.1.0 If all of the above worked, congratulations! Of course you are not reading this for just celebration, but you wanted to know more about what happened under the hood. uv also supports publishing from/to anywhere with credentials. But, if possible, publishing with a trusted publisher unburdens you from credential management. In the release.yaml , note caching is explicitly disabled. This makes the release step more dependable, because by accident wrong dependencies could end up in the cache. Also deliberately by the way, so this is also a security measure. If you want to know more, lookup something like: GitHub Actions cache poisoning. Setting the pypi environment did not add security in the steps above. You can (and should) use it for that way though. This walkthrough is getting very long already, so more on how to set that up is in the extra guides . Also in the extra guides you can find the minimal steps on how to build and publish a CLI from this template. Unless your project will be really simple (which it never will be), I would advise to make separate lib and app/cli projects for business logic and integration respectively. Otherwise you could just use a simple script with inline dependencies . Final important note: Before publishing a next version, don't forget to version bump in the pyproject.toml and forward that to the lockfile with uv lock . Then of course git add, commit and push, and then you should be good to go for publishing again. Hopefully these steps will be automated in a future version of this template. Bonus: the ptpython REPL Get back to the command-line in your local clone. Execute uvx --with-editable . ptpython ; you should now be in ptpython's REPL. Type from <YOUR_PROJECT_SLUG> import hello and enter; note the hinting and coloring to help you. Type hello(someone=\"me\") and enter; should output 'Hello me from <YOUR_PROJECT_SLUG>!' . Execute exit() to exit the REPL. Tinkering within context You could simply run uv run python and tinker away in your virtual env, but quality of life in ptpython's REPL is simply much better. Directly running uvx ptpython doesn't work here, because uv's whole point is env separation. To give your current project's context to ptpython you can run uvx --with-editable . ptpython . --with-editable is used instead of --with to make uv look at the latest local updates of your code (including its dependencies!). The updated happy path workflow When you completed all the above successfully, pat yourself on the back for me. The real reward is of course a reliable way of developing your Python project. Now that you went through all the bootstrapping needed only once, your development happy flow may look something like this: Download dependencies (if you need any): uv add some_lib_you_need Develop (optional, tinker: uvx --with-editable . ptpython ) QA: Format: uv run ruff format (or uv run ruff format --diff if you want to check the proposed changes first) Lint: uv run ruff check (or simply uv run ruff check --fix if, you also, like to live dangerously) Type check: uv run mypy Test: uv run python -m unittest Build: uv build (just to test it works) Preview documentation: uvx --with mkdocstrings[python] mkdocs serve Publish package: kickoff the Publish to PyPI workflow in GitHub Actions Publish documentation: uvx --with mkdocstrings[python] mkdocs gh-deploy Or even better, create your own workflow that exactly caters to your project's needs. Happy coding \ud83e\udd17","title":"Walkthrough"},{"location":"walkthrough/#walkthrough","text":"Some things in usage might require a little more effort on the first run. Let's go over the bootstrapping and the development cycle in full detail. In this walkthrough we are going to create a Python library and publish it to PyPI. While doing so we will do all the steps you would normally do during a feature development as well. Also, we will publish the project's documentation to GitHub Pages. You are encouraged to go through this walkthrough twice. Upon first run, only execute the instructions and ignore all the explanations underneath. Then reread this page in full to get a better grasp of what this template is setting you up for you.","title":"Walkthrough"},{"location":"walkthrough/#initializing-your-project","text":"Instructions: Create a repository in GitHub; do not add any additional files upon creation, like .gitignore, LICENSE etc.; make sure you take a project name not already on PyPI, if you want to follow this walkthrough all the way to publishing there. Clone the repo to your development environment. Execute this command from the directory directly above: uvx cruft create -f --checkout latest https://github.com/schubergphilis/paleofuturistic_python . Answer the questions; project_slug should be the same as the GitHub repository name you chose. cd to your project directory; execute git add --all , git commit -m \"initial commit\" and git push . Navigate to https://github.com/<YOUR_GITHUB_HANDLE>/<YOUR_PROJECT_SLUG>/actions . See that the quality assurance CI fails; you will fix this in the next instructions.","title":"Initializing your project"},{"location":"walkthrough/#managing-boilerplate","text":"cruft ( cookiecutter under its hood) is a tool for managing boilerplate. Like you did, new projects can be instantiated from a template with it. An even more amazing function is that it can update a project's boilerplate when the template changes (also this Paleofuturistic one!). See the extra guides for more information on that. It might still be noteworthy to point out a few things in the command you used: uvx cruft create -f --checkout latest https://github.com/schubergphilis/paleofuturistic_python The --checkout latest in there should speak for itself. Now mind the -f . cruft does not allow editing an existing directory by default for safety. Because we just cloned an empty repository, we can assume to be safe though. Other options to get to the same state would be: create the project with directory from the template with cruft, cd to it; git init, add all, commit, set the remote and push. create the project with directory from the template with cruft, copy the contents to a cloned repository; git add all, commit and push.","title":"Managing boilerplate"},{"location":"walkthrough/#reviewing-gitignore-and-license","text":"If you had wanted another license than Apache, you have probably already chosen one and can easily override the templated one (if you do, do it in the pyproject.toml as well). Maybe take a look at the .gitignore, maybe not; it's fine; I promise.","title":"Reviewing .gitignore and LICENSE"},{"location":"walkthrough/#dependency-management","text":"Instructions: Get back to the command-line in your local clone. Execute: uv sync --all-extras --dev . Execute: git add --all , git commit -m \"lock initial dependencies\" and git push . Navigate to https://github.com/<YOUR_GITHUB_HANDLE>/<YOUR_PROJECT_SLUG>/actions . See that the quality assurance CI now succeeds; what it's exactly doing, you will find out in the next instructions.","title":"Dependency management"},{"location":"walkthrough/#dependencies-in-environments","text":"Usually a lot or even more of the low-level functionality you need for what you want to develop is already available. Luckily, reeling that good stuff in is one of uv's strengths. The --all-extras --dev flags from the uv command above triggers downloading optional and development dependencies respectively. After that you can add dependencies like for example uv add requests or uv add --dev pytest for dev dependencies. These commands do everything you would hope they would do by default. Yes, that includes caching and project-based environment isolation. For starters just adding some dependencies from PyPI is probably all you want. All the other things you would want from (uv's) dependency management you can always look into later. By now you might have already guessed that uv acts on dependencies in your environment and uvx is meant for tools that live outside of it. A reminder: add the names of the public features you develop to the __all__ list in __init__.py . This way others (that includes your unittest runs) can conveniently access them upon importing your module.","title":"Dependencies in environments"},{"location":"walkthrough/#quality-assurance","text":"Instructions: Get back to the command-line in your local clone. Execute uv run ruff format --diff ; should output 4 files already formatted . Execute uv run ruff check ; should output All checks passed! . Execute uv run mypy ; should output Success: no issues found in 2 source files . Execute uv run python -m unittest ; gives multiline output, should end with OK . Execute git status ; gives multiline output, should end with nothing to commit, working tree clean .","title":"Quality assurance"},{"location":"walkthrough/#formatting-linting-type-checking-and-testing","text":"The steps above are the minimal steps to assure quality in any software project. When they output that everything is as expected, they should also leave the codebase unchanged. The dependencies for these steps are pinned in the pyproject.toml to make sure they run the same way locally as in the pipeline. The pipeline can run quite quick upon repetition, because caching is enabled, see .github/workflows/quality_assurance.yaml . Formatting ( uv run ruff format --diff ), type checking ( uv run mypy ) and testing ( uv run python -m unittest ) should speak for themselves. The ruff formatter, mypy and Python's build-in testing library are ubiquitous and easy to use. Only mypy has a minimal amount of config in the pyproject.toml that make it a bit more specific and tight. You can get into the weeds very fast with linting ( uv run ruff check ) though. If you go with the flow of this template it's probably going to work out fine for your first 1,000 commits or so. And by that time you can probably figure out how to stop a pesky linter from undoing your intricacies, so my advice would be to not give it too much thought. (If you feel like getting into the weeds early though, have at you .) Small thing worth mentioning is that the pyproject.toml is setup such that the ruff linter and formatter should not contradict each other. Also, the activated linting rules are a little more than the default, mainly because isort is really convenient.","title":"Formatting, linting, type checking and testing"},{"location":"walkthrough/#building-your-package","text":"Instructions: Get back to the command-line in your local clone. Execute uv build ; gives multiline output, should end with Successfully built dist/<YOUR_PROJECT_SLUG>-0.1.0-py3-none-any.whl . Execute git status ; gives multiline output, should end with nothing to commit, working tree clean .","title":"Building your package"},{"location":"walkthrough/#the-artifacts-to-distribute","text":"uv has its own build backend nowadays. It works only for pure Python projects at the moment, but that's probably good enough for most projects. If you have more special needs you probably already know what you want and can configure that under [build-system] in the pyproject.toml . Also, uv is not so sure the build backend won't significantly change in the future. For that reason there is an upper limit in the pyproject.toml on uv's minor version as per their best practices. (If you ever update uv beyond that version and this breaks your build step for that reason, check back on this template and update .) Other than that, this step should simply be a uv build command that just works. Locally you will probably only run this command to validate it works though. Eventually it's a pipeline that should build and publish.","title":"The artifacts to distribute"},{"location":"walkthrough/#previewing-and-publishing-your-documentation","text":"Instructions: Get back to the command-line in your local clone. Execute uvx --with mkdocstrings[python] mkdocs build ; gives multiline output, should end with INFO - Documentation built in <X> seconds . Execute uvx --with mkdocstrings[python] mkdocs serve ; gives multiline output, should end with INFO - <X> Serving on http://127.0.0.1:8000/ ; Navigate to http://127.0.0.1:8000/ ; some rudimentary documentation should be there. Get back to the command-line in your local clone; terminate the serving process. Execute uvx --with mkdocstrings[python] mkdocs gh-deploy ; gives multiline output, should end with INFO - Your documentation should shortly be available at: https://<YOUR_GITHUB_HANDLE>.github.io/<YOUR_PROJECT_SLUG>/ . Navigate to https://github.com/<YOUR_GITHUB_HANDLE>/<YOUR_PROJECT_SLUG>/actions ; a GitHub Action should be running to deploy you docs. Wait until the action finishes then navigate to https://<YOUR_GITHUB_HANDLE>.github.io/<YOUR_PROJECT_SLUG>/ ; it should display the same documentation you just served locally. Get back to the command-line in your local clone. Execute git status ; gives multiline output, should end with nothing to commit, working tree clean .","title":"Previewing and publishing your documentation"},{"location":"walkthrough/#a-very-feature-rich-static-website","text":"Let's first explain a bit about that magic --with in the commands above. It injects additional dependencies into the environment in this case mkdocstrings with its python add-on. Now, in your project directory go to docs/index.md and see how little was needed to produce such a fantastic skeleton for documentation. You do need to keep every docstring nice and tidy to make that work though. I found mkdocstrings works best with numpy style docs, so that's the template's default. You can change that and more in the mkdocs.yaml . Don't try to understand all of that at once... MkDocs offers far more than everything you accomplished above, especially combined with even more plugins. See for yourself. Personal favorite out of the box: watch files. Others might particularly like automated publishing to other documentation hosting parties than GitHub Pages.","title":"A very feature-rich static website"},{"location":"walkthrough/#publishing-your-python-package-to-pypi","text":"Instructions: Navigate to https://github.com/<YOUR_GITHUB_HANDLE>/<YOUR_PROJECT_SLUG>/settings/environments . Create an environment named pypi . Go to PyPI and login; if you have no account there, create one first. Configure a trusted publisher . Go to https://github.com/<YOUR_GITHUB_HANDLE>/<YOUR_PROJECT_SLUG>/actions/workflows/release.yaml and run the workflow. Wait for the workflow to finish, then get back to the command-line. Execute uv run --isolated --no-project --with <YOUR_PROJECT_SLUG> python -c \"from <YOUR_PROJECT_SLUG> import hello; print(hello())\" ; should output Hello you from <YOUR_PROJECT_SLUG>! .","title":"Publishing your Python package to PyPI"},{"location":"walkthrough/#beyond-v010","text":"If all of the above worked, congratulations! Of course you are not reading this for just celebration, but you wanted to know more about what happened under the hood. uv also supports publishing from/to anywhere with credentials. But, if possible, publishing with a trusted publisher unburdens you from credential management. In the release.yaml , note caching is explicitly disabled. This makes the release step more dependable, because by accident wrong dependencies could end up in the cache. Also deliberately by the way, so this is also a security measure. If you want to know more, lookup something like: GitHub Actions cache poisoning. Setting the pypi environment did not add security in the steps above. You can (and should) use it for that way though. This walkthrough is getting very long already, so more on how to set that up is in the extra guides . Also in the extra guides you can find the minimal steps on how to build and publish a CLI from this template. Unless your project will be really simple (which it never will be), I would advise to make separate lib and app/cli projects for business logic and integration respectively. Otherwise you could just use a simple script with inline dependencies . Final important note: Before publishing a next version, don't forget to version bump in the pyproject.toml and forward that to the lockfile with uv lock . Then of course git add, commit and push, and then you should be good to go for publishing again. Hopefully these steps will be automated in a future version of this template.","title":"Beyond v0.1.0"},{"location":"walkthrough/#bonus-the-ptpython-repl","text":"Get back to the command-line in your local clone. Execute uvx --with-editable . ptpython ; you should now be in ptpython's REPL. Type from <YOUR_PROJECT_SLUG> import hello and enter; note the hinting and coloring to help you. Type hello(someone=\"me\") and enter; should output 'Hello me from <YOUR_PROJECT_SLUG>!' . Execute exit() to exit the REPL.","title":"Bonus: the ptpython REPL"},{"location":"walkthrough/#tinkering-within-context","text":"You could simply run uv run python and tinker away in your virtual env, but quality of life in ptpython's REPL is simply much better. Directly running uvx ptpython doesn't work here, because uv's whole point is env separation. To give your current project's context to ptpython you can run uvx --with-editable . ptpython . --with-editable is used instead of --with to make uv look at the latest local updates of your code (including its dependencies!).","title":"Tinkering within context"},{"location":"walkthrough/#the-updated-happy-path-workflow","text":"When you completed all the above successfully, pat yourself on the back for me. The real reward is of course a reliable way of developing your Python project. Now that you went through all the bootstrapping needed only once, your development happy flow may look something like this: Download dependencies (if you need any): uv add some_lib_you_need Develop (optional, tinker: uvx --with-editable . ptpython ) QA: Format: uv run ruff format (or uv run ruff format --diff if you want to check the proposed changes first) Lint: uv run ruff check (or simply uv run ruff check --fix if, you also, like to live dangerously) Type check: uv run mypy Test: uv run python -m unittest Build: uv build (just to test it works) Preview documentation: uvx --with mkdocstrings[python] mkdocs serve Publish package: kickoff the Publish to PyPI workflow in GitHub Actions Publish documentation: uvx --with mkdocstrings[python] mkdocs gh-deploy Or even better, create your own workflow that exactly caters to your project's needs. Happy coding \ud83e\udd17","title":"The updated happy path workflow"}]}